{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. FETCHING DATASET FROM DRIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "train_df=pandas.read_csv(\"Corona_NLP_train.csv\",encoding='latin-1')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44953</td>\n",
       "      <td>NYC</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44954</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>44955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>Find out how you can protect yourself and love...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44956</td>\n",
       "      <td>Chicagoland</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>44957</td>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "      <td>03-03-2020</td>\n",
       "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName             Location     TweetAt  \\\n",
       "0         1       44953                  NYC  02-03-2020   \n",
       "1         2       44954          Seattle, WA  02-03-2020   \n",
       "2         3       44955                  NaN  02-03-2020   \n",
       "3         4       44956          Chicagoland  02-03-2020   \n",
       "4         5       44957  Melbourne, Victoria  03-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  TRENDING: New Yorkers encounter empty supermar...  Extremely Negative  \n",
       "1  When I couldn't find hand sanitizer at Fred Me...            Positive  \n",
       "2  Find out how you can protect yourself and love...  Extremely Positive  \n",
       "3  #Panic buying hits #NewYork City as anxious sh...            Negative  \n",
       "4  #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df=pandas.read_csv(\"Corona_NLP_test.csv\")\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.TRAINING OF DATASET WITH PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "\n",
    "def train_logistic_regression(sentences, labels, max_features=5000, test_size=0.3, random_state=42, max_iter=1000):\n",
    "    \"\"\"\n",
    "    Trains a Logistic Regression model for text classification.\n",
    "\n",
    "    Args:\n",
    "        sentences (list): List of text sentences.\n",
    "        labels (list): List of corresponding labels.\n",
    "        max_features (int): Maximum number of features for TF-IDF.\n",
    "        test_size (float): Proportion of the dataset to include in the test split.\n",
    "        random_state (int): Seed for the random number generator.\n",
    "        max_iter (int): Maximum number of iterations for Logistic Regression.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Trained Logistic Regression model and TF-IDF vectorizer.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Feature Extraction (TF-IDF)\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "    X = vectorizer.fit_transform(sentences)\n",
    "\n",
    "    # 2. Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        labels,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    # 3. Model Training\n",
    "    model = LogisticRegression(max_iter=max_iter, solver='lbfgs', multi_class='auto')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 4. Model Evaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return model, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.TESTING OF MODEL/ PREDICTING FROM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_logistic_regression(model, vectorizer, new_sentences):\n",
    "    \"\"\"\n",
    "    Makes predictions using a trained Logistic Regression model.\n",
    "\n",
    "    Args:\n",
    "        model (LogisticRegression): Trained Logistic Regression model.\n",
    "        vectorizer (TfidfVectorizer): Trained TF-IDF vectorizer.\n",
    "        new_sentences (list): List of new sentences to predict.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Predicted labels.\n",
    "    \"\"\"\n",
    "    new_X = vectorizer.transform(new_sentences)\n",
    "    new_predictions = model.predict(new_X)\n",
    "    return new_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.SAVING AND LOADING OF MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, vectorizer, model_filename=\"logistic_model.pkl\", vectorizer_filename=\"tfidf_vectorizer.pkl\"):\n",
    "    \"\"\"\n",
    "    Saves the trained model and vectorizer to disk.\n",
    "\n",
    "    Args:\n",
    "        model (LogisticRegression): Trained Logistic Regression model.\n",
    "        vectorizer (TfidfVectorizer): Trained TF-IDF vectorizer.\n",
    "        model_filename (str): Filename to save the model.\n",
    "        vectorizer_filename (str): Filename to save the vectorizer.\n",
    "    \"\"\"\n",
    "    with open(model_filename, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    with open(vectorizer_filename, 'wb') as f:\n",
    "        pickle.dump(vectorizer, f)\n",
    "\n",
    "def load_model(model_filename=\"logistic_model.pkl\", vectorizer_filename=\"tfidf_vectorizer.pkl\"):\n",
    "    \"\"\"\n",
    "    Loads the trained model and vectorizer from disk.\n",
    "\n",
    "    Args:\n",
    "        model_filename (str): Filename of the saved model.\n",
    "        vectorizer_filename (str): Filename of the saved vectorizer.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Loaded Logistic Regression model and TF-IDF vectorizer.\n",
    "    \"\"\"\n",
    "    with open(model_filename, 'rb') as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "    with open(vectorizer_filename, 'rb') as f:\n",
    "        loaded_vectorizer = pickle.load(f)\n",
    "    return loaded_model, loaded_vectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.MAIN SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example usage:\n",
    "test_df = test_df.drop(\n",
    "    columns=['UserName','ScreenName','Location','TweetAt'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = train_df['OriginalTweet'].tolist()\n",
    "labels = train_df['Sentiment'].tolist()\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gtu project\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5677\n",
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Extremely Negative       0.61      0.47      0.53      1572\n",
      "Extremely Positive       0.68      0.54      0.60      1989\n",
      "          Negative       0.50      0.52      0.51      3005\n",
      "           Neutral       0.63      0.67      0.65      2292\n",
      "          Positive       0.53      0.60      0.56      3490\n",
      "\n",
      "          accuracy                           0.57     12348\n",
      "         macro avg       0.59      0.56      0.57     12348\n",
      "      weighted avg       0.57      0.57      0.57     12348\n",
      "\n",
      "Predictions: ['Neutral' 'Positive' 'Extremely Positive' ... 'Neutral'\n",
      " 'Extremely Negative' 'Positive']\n",
      "Loaded predictions: ['Neutral' 'Positive' 'Extremely Positive' ... 'Neutral'\n",
      " 'Extremely Negative' 'Positive']\n"
     ]
    }
   ],
   "source": [
    "#training of model\n",
    "model, vectorizer = train_logistic_regression(sentences, labels)\n",
    "\n",
    "#testing of model\n",
    "new_sentences = test_df['OriginalTweet'].tolist()\n",
    "predictions = predict_logistic_regression(model, vectorizer, new_sentences)\n",
    "print(\"Predictions:\", predictions)\n",
    "\n",
    "#Saving model\n",
    "save_model(model, vectorizer)\n",
    "\n",
    "loaded_model, loaded_vectorizer = load_model()\n",
    "\n",
    "loaded_predictions = predict_logistic_regression(loaded_model, loaded_vectorizer, new_sentences)\n",
    "print(\"Loaded predictions:\", loaded_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE FINAL CODE AFTER APPLYING PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gtu project\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7265\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.65      0.71      1572\n",
      "           1       0.81      0.69      0.74      1989\n",
      "           2       0.69      0.69      0.69      3005\n",
      "           3       0.76      0.81      0.78      2292\n",
      "           4       0.68      0.76      0.72      3490\n",
      "\n",
      "    accuracy                           0.73     12348\n",
      "   macro avg       0.75      0.72      0.73     12348\n",
      "weighted avg       0.73      0.73      0.73     12348\n",
      "\n",
      "Predictions: ['Neutral' 'Positive' 'Extremely Positive' ... 'Neutral'\n",
      " 'Extremely Negative' 'Positive']\n",
      "Loaded predictions: ['Neutral' 'Positive' 'Extremely Positive' ... 'Neutral'\n",
      " 'Extremely Negative' 'Positive']\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# Load the data\n",
    "train_df = pandas.read_csv(\"Corona_NLP_train.csv\", encoding='latin-1')\n",
    "test_df = pandas.read_csv(\"Corona_NLP_test.csv\")\n",
    "\n",
    "# Data preprocessing\n",
    "train_df = train_df.drop(columns=['UserName', 'ScreenName', 'Location', 'TweetAt'], axis=1)\n",
    "\n",
    "# Prepare sentences and labels\n",
    "sentences = train_df['OriginalTweet'].tolist()\n",
    "labels = train_df['Sentiment'].tolist()\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000)),\n",
    "    ('clf', LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='auto'))\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(sentences, labels_encoded)\n",
    "\n",
    "# Make predictions on test data\n",
    "test_sentences = test_df['OriginalTweet'].tolist()\n",
    "predictions_encoded = pipeline.predict(test_sentences)\n",
    "\n",
    "# Decode predictions back to original labels\n",
    "predictions = label_encoder.inverse_transform(predictions_encoded)\n",
    "\n",
    "# Evaluate the pipeline\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentences, labels_encoded, test_size=0.3, random_state=42)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Predictions:\", predictions)\n",
    "\n",
    "# Save the pipeline and label encoder\n",
    "with open('sentiment_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump((pipeline, label_encoder), f)\n",
    "\n",
    "# Load the pipeline and label encoder\n",
    "with open('sentiment_pipeline.pkl', 'rb') as f:\n",
    "    loaded_pipeline, loaded_label_encoder = pickle.load(f)\n",
    "\n",
    "# Make predictions using loaded pipeline\n",
    "loaded_predictions_encoded = loaded_pipeline.predict(test_sentences)\n",
    "loaded_predictions = loaded_label_encoder.inverse_transform(loaded_predictions_encoded)\n",
    "print(\"Loaded predictions:\", loaded_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
